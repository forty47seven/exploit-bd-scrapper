import os
import requests

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select

# path for the selenium driver, the driver is needed for the application to work
os.environ['PATH'] += r"C:/selenium_driver"

url = 'https://www.exploit-db.com/'


def get_paper_info(num):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element0 = driver.find_element(By.NAME, "exploits-table_length")
    select = Select(element0)

    select.select_by_value('120')

    db = []
    for i in range(num):
        paper_type = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[6]/a").get_attribute('innerHTML')
        platform = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[7]/a").get_attribute('innerHTML')
        author = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[8]/a").get_attribute('innerHTML')
        html = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[5]").get_attribute('innerHTML')
        file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]
        download_link = f"{url}download{file_index}"

        headers = {'User-Agent': 'Mozilla/5.0'}
        r = requests.get(f'{url}download{file_index}', headers=headers, verify=False)

        contains_name = r.headers.get('Content-Disposition')

        for j in contains_name:
            if j == '.':
                ext = contains_name[contains_name.index('.'):]
        title = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[5]/a").get_attribute('innerHTML')
        for letter in title:
            if letter == '/' or '\\' or ':' or '|' or '?' or '*' or '<' or '>':
                title = title.split(' -')[0]
        title = f'{title}{ext}'
        
        my_dict = {'title': title, 'paper type': paper_type, 'platform': platform, 'author': author, 'download_link': download_link, 'file_index': file_index}

        db.append(my_dict)
    return db

def download(file_name, file_index):
    headers = {'User-Agent': 'Mozilla/5.0'}
    r = requests.get(f'{url}download{file_index}', headers=headers, verify=False)

    with open(f"papers/{file_name}", 'wb') as f:
        f.write(r.content)
    

def my_recent(num):
    paper_info = get_paper_info(num=num)

    for paper in paper_info:
        file_index = paper['file_index']
        file_name = paper['title']

        download(file_name=file_name, file_index=file_index)
    return paper_info

def recent(num):
    paper_info = get_paper_info(num=int(num))

    title_list = []
    download_link_list = []
    for paper in paper_info:
        title_list.append(paper['title'])
        download_link_list.append(paper['download_link'])
    recent_list = zip(title_list, download_link_list)
    return_dict = {'recent_list': recent_list}
    return return_dict

def search_download(search_key):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element = driver.find_element(By.XPATH, "//div[@class='dataTables_filter']/label/input")

    element.send_keys(search_key, Keys.ENTER)

    element1 = driver.find_element(By.XPATH, f"//tbody/tr[1]/td[5]")
    element2 = driver.find_element(By.XPATH, f"//tbody/tr[1]/td[5]/a")

    html = element1.get_attribute('innerHTML')
    file_name = element2.get_attribute('innerHTML')

    file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]

    download_link = f'{url}download{file_index}'
    return_dict = {'title': file_name, 'download_link': download_link}
    return return_dict

def multi_search(search_key):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element = driver.find_element(By.XPATH, "//div[@class='dataTables_filter']/label/input")

    element.send_keys(str(search_key), Keys.ENTER)

    found = 0
    return_dict = {}
    title_list = []
    download_link_list = []
    for i in range(10):
        try:
            element0 = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[5]/a")
            d_title = f"{element0.get_attribute('innerHTML')}"
            title_list.append(d_title)

            element1 = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[5]")
            html = element1.get_attribute('innerHTML')

            file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]
            download_link = f'{url}download{file_index}'

            download_link_list.append(download_link)

            found = 1
        except:
            if found == 0:
                return_dict = 0
                return return_dict
            break
    if found != 0:
        multi_list = zip(title_list, download_link_list)
        return_dict = {'multi_list': multi_list}
        return return_dict


'''
def get_fileTitleAndIndexes(for_index, for_title):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element0 = driver.find_element(By.NAME, "exploits-table_length")
    select = Select(element0)

    select.select_by_value('120')
    index_list = []
    for i in range(int(num)):
        element1 = driver.find_element(By.XPATH, f"//tbody/tr[{i}+1]/td[5]")

        html = element1.get_attribute('innerHTML')

        file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]
        
        index_list.append(file_index)

    name_list = []
    for i in range(int(num)):
        element2 = driver.find_element(By.XPATH, f"//tbody/tr[{i}+1]/td[5]/a")
        paper_name = element2.get_attribute('innerHTML')
        name_list.append(paper_name)

    paper_dict = {'index': index_list, 'name': name_list}
    return paper_dict

    # get_paper_info(num=num)

    driver.close()
'''
