import os
import requests

from selenium import webdriver
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import Select

os.environ['PATH'] += r"C:/selenium_driver"

url = 'https://www.exploit-db.com/'

def get_paper_info(num):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)

    db = []
    for i in range(num):
        title = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[5]/a").get_attribute('innerHTML')
        paper_type = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[6]/a").get_attribute('innerHTML')
        platform = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[7]/a").get_attribute('innerHTML')
        author = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[8]/a").get_attribute('innerHTML')
        html = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}+1]/td[5]").get_attribute('innerHTML')
        file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]

        my_dict = {'title': title, 'paper type': paper_type, 'platform': platform, 'author': author, 'file_index': file_index}

        db.append(my_dict)
    return db

def download(file_name, file_index):
    headers = {'User-Agent': 'Mozilla/5.0'}
    r = requests.get(f'{url}download{file_index}', headers=headers, verify=False)

    contains_name = r.headers.get('Content-Disposition')

    for j in contains_name:
        if j == '.':
            ext = contains_name[contains_name.index('.'):]

    with open(f'{file_name}{ext}', 'wb') as f:
        f.write(r.content)

def get_fileNamesAndIndexes(num):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element0 = driver.find_element(By.NAME, "exploits-table_length")
    select = Select(element0)

    select.select_by_value('120')
    index_list = []
    for i in range(int(num)):
        element1 = driver.find_element(By.XPATH, f"//tbody/tr[{i}+1]/td[5]")

        html = element1.get_attribute('innerHTML')

        file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]
        
        index_list.append(file_index)

    name_list = []
    for i in range(int(num)):
        element2 = driver.find_element(By.XPATH, f"//tbody/tr[{i}+1]/td[5]/a")
        paper_name = element2.get_attribute('innerHTML')
        name_list.append(paper_name)

    paper_dict = {'index': index_list, 'name': name_list}
    return paper_dict

    # get_paper_info(num=num)

    driver.close()

def multi_download(num):
    paper_info = get_paper_info(num=num)

    for paper in paper_info:
        file_index = paper['file_index']
        file_name = paper['title']

        download(file_name=file_name, file_index=file_index)

def search_download(search_key):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element = driver.find_element(By.XPATH, "//div[@class='dataTables_filter']/label/input")

    element.send_keys(search_key, Keys.ENTER)

    element1 = driver.find_element(By.XPATH, f"//tbody/tr[1]/td[5]")
    element2 = driver.find_element(By.XPATH, f"//tbody/tr[1]/td[5]/a")

    html = element1.get_attribute('innerHTML')
    file_name = element2.get_attribute('innerHTML')

    file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]

    download(file_name=file_name, file_index=file_index)

def multi_search_download(search_key):
    driver = webdriver.Chrome()
    driver.get(url)

    driver.implicitly_wait(30)
    element = driver.find_element(By.XPATH, "//div[@class='dataTables_filter']/label/input")

    element.send_keys(str(search_key), Keys.ENTER)

    found = 0
    for i in range(10):
        try:
            element0 = driver.find_element(By.XPATH, f"//tbody/tr[{i+1}]/td[5]/a")
            print(f"{i+1} to download - {element0.get_attribute('innerHTML')}")
            found += 1
        except:
            if found == 0:
                print('No results found')
            break
    if found != 0:
        print('0 to download all')
    my_file = int(input('Choose file: '))

    if my_file == 0:
        multi_download(found)
    else:
        element0 = driver.find_element(By.XPATH, f"//tbody/tr[{my_file}]/td[5]")
        html = element0.get_attribute('innerHTML')

        file_name = driver.find_element(By.XPATH, f"//tbody/tr[{my_file}]/td[5]/a").get_attribute('innerHTML')
        file_index = html.split('"')[1].split('"')[0].split('/exploits')[1]
        
        download(file_name=file_name, file_index=file_index)

